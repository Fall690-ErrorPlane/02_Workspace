{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DrawBoundingBoxesOnImage.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQysKcso0Zaw"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "from scipy.ndimage import measurements\n",
        "import skimage.exposure\n",
        "from sklearn import linear_model\n",
        "from typing import Any, Dict, Iterable, List, Mapping, Optional, Tuple\n",
        "import gdal\n",
        "import gdalconst\n",
        "import copy\n",
        "import pandas as pd\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.io import read_image\n",
        "from torchvision.utils import draw_bounding_boxes"
      ],
      "metadata": {
        "id": "dCpt4TOtAb7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import image\n"
      ],
      "metadata": {
        "id": "YIuK8uaS8hV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import ndimage"
      ],
      "metadata": {
        "id": "QT0J0ew-3gIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive # m.p. added cell, this cell mounts your google drive to the colab\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xf5W_T0t0wXr",
        "outputId": "e23c0172-d233-48eb-dda9-c83f2b50cf6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The code in this cell takes the JSON files with the bounding box coordinates and swaps x2, y1, and writes the classifier, boudning box coordinates\n",
        "#filename and width, height \n",
        "\n",
        "bbox_path = '/content/gdrive/MyDrive/json_image_files/json_files_with_bbox_data'\n",
        "yolo_path = '/content/gdrive/MyDrive/yoloV5_format_file'\n",
        "\n",
        "\n",
        "for filename in os.listdir(bbox_path):\n",
        "  f = open(os.path.join(bbox_path,filename))\n",
        "  indiv_json_file = json.loads(f.read()) # reads file in as a python object\n",
        "  list_of_polygons = indiv_json_file['polygons']\n",
        "  num_of_contrails_infile = (len(list_of_polygons))\n",
        "  current_contrail = 0\n",
        "  image_size = 1400\n",
        "  classifier = np.array([0])\n",
        "\n",
        "  while current_contrail < num_of_contrails_infile:\n",
        "    #print(list_of_polygons[current_contrail][-1])  #verification\n",
        "    if len(list_of_polygons[current_contrail][-1]) < 4:\n",
        "      print(filename)\n",
        "      current_contrail = current_contrail + 1\n",
        "      continue\n",
        "    #perform swap\n",
        "    x2 = list_of_polygons[current_contrail][-1][1]\n",
        "    y1 = list_of_polygons[current_contrail][-1][2] \n",
        "    temp = copy.deepcopy(list_of_polygons[current_contrail][-1][1]) # store x2 in temp\n",
        "    x2 = copy.deepcopy(y1)\n",
        "    y1 = copy.deepcopy(temp)\n",
        "    list_of_polygons[current_contrail][-1][1] = x2\n",
        "    list_of_polygons[current_contrail][-1][2] = y1\n",
        "    #print(list_of_polygons[current_contrail][-1]) # verification\n",
        "\n",
        "    fileType = '.txt'\n",
        "    textfile_name_list = filename.split(\".\") \n",
        "    textfile_name = textfile_name_list[0]+ fileType\n",
        "\n",
        "    contrail1 = np.array(list_of_polygons[current_contrail][-1]) # convert list to a numpy arry\n",
        "    contrail1 = contrail1/image_size  # normalize bounding box\n",
        "    #print(contrail1) # verification \n",
        "    y = open(os.path.join(yolo_path,textfile_name), 'a') # open text file\n",
        "    classifier = list(classifier)\n",
        "    contrail1 = list(contrail1)\n",
        "    for num in classifier:\n",
        "      y.write(str(num))\n",
        "      y.write(\" \")\n",
        "    for number in contrail1:\n",
        "      y.write(str(number))\n",
        "      y.write(\" \")\n",
        "    y.write(\" \\n\")\n",
        "    current_contrail = current_contrail + 1\n",
        "    \n",
        "    #print(\" \")\n",
        "  #print(current_contrail)\n",
        "  "
      ],
      "metadata": {
        "id": "X053r9zL1bgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # sample file names to test code\n",
        "                                          LC08_L1TP_034022_20180729_20180814_01_T1_B10\n",
        "\n",
        "                                          LC08_L1TP_032037_20180816_20180829_01_T1_B10\n",
        "\n",
        "                                          LC08_L1TP_025037_20180308_20180320_01_T1_B10\n",
        "\n",
        "                                          LC08_L1TP_032037_20180816_20180829_01_T1_B10\n",
        "\n",
        "                                          LC08_L1TP_006028_20180709_20180717_01_T1_B10\n",
        "\n",
        "                                          LC08_L1TP_011048_20181117_20181129_01_T1_B10"
      ],
      "metadata": {
        "id": "ZMfh61B5wqGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This cell opens an Landsat-8 image png  that has polygon annotations and converts it to 3 channel RBG, the images from landsat-8 are 4 channel because they have alpha\n",
        "img = Image.open(('/content/gdrive/MyDrive/tif_image_files/annotated_images_with_contrails/LC08_L1TP_011048_20181117_20181129_01_T1_B10.png')).convert('RGB')"
      ],
      "metadata": {
        "id": "1BYmVkltId4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#save the converted RGB image\n",
        "img.save('img.jpeg')"
      ],
      "metadata": {
        "id": "sWKrWBKOOkue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(img.width) # check the width \n",
        "print(img.height)# check the height"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w14-r8t0ACcM",
        "outputId": "71209296-9724-419b-e636-50be4dcd6a61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1440\n",
            "1440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = img.resize((1440, 1470)) # resize the image to keep aspect ratio of the annotated image"
      ],
      "metadata": {
        "id": "qGMGIrR1S8_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(img.width)# verify the resize worked\n",
        "print(img.height)# verify the resize worked\n",
        "img.save('img.jpeg') # save the resized image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ov3rdZ9lVWC7",
        "outputId": "f50c5cb4-aadc-474f-b9f9-1e425fc70a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1440\n",
            "1470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img = read_image('/content/img.jpeg') # read in the resized image as a tensor\n",
        "\n"
      ],
      "metadata": {
        "id": "05aNkp7Z-V4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell is a testing if bounding boxes enclose the polygon annotations, since this is a test, not all boxes are assigned from the polygons\n",
        "json_file = '/content/gdrive/MyDrive/json_image_files/json_files_with_bbox_data/LC08_L1TP_011048_20181117_20181129_01_T1_B10.json'\n",
        "\n",
        "f = open('/content/gdrive/MyDrive/json_image_files/json_files_with_bbox_data/LC08_L1TP_011048_20181117_20181129_01_T1_B10.json')\n",
        "indiv_json_file = json.loads(f.read()) # reads file in as a python object\n",
        "list_of_polygons = indiv_json_file['polygons']\n",
        "num_of_contrails_infile = (len(list_of_polygons))\n",
        "print(num_of_contrails_infile) # check how many contrails in the scene\n",
        "one_box0 = list_of_polygons[0][-1]\n",
        "one_box1 = list_of_polygons[1][-1]\n",
        "one_box2 = list_of_polygons[2][-1]\n",
        "\n",
        "one_box3 = list_of_polygons[3][-1]\n",
        "one_box4 = list_of_polygons[4][-1]\n",
        "\n",
        "one_box5 = list_of_polygons[5][-1]\n",
        "\n",
        "# not checking these polygons since this is just a test, only checking the 1st 6 contrails\n",
        "\"\"\"\n",
        "one_box6 = list_of_polygons[6][-1]\n",
        "one_box7 = list_of_polygons[7][-1]\n",
        "one_box8 = list_of_polygons[8][-1]\n",
        "one_box9 = list_of_polygons[9][-1]\n",
        "one_box10 = list_of_polygons[10][-1]\n",
        "one_box11 = list_of_polygons[11][-1]\n",
        "one_box12 = list_of_polygons[12][-1]\n",
        "one_box13 = list_of_polygons[13][-1]\n",
        "one_box14 = list_of_polygons[14][-1]\n",
        "\"\"\"\n",
        "\n",
        "# Assigning the xmin, xmax, ymin, ymax for 1st 6 polygons in scene\n",
        "# you MUST run the image name through the Landsat-8_contrails code to get the original image size\n",
        "# each image is a different width and height\n",
        "\n",
        "b0 = np.array(one_box0) #(X1[0], X2[1], Y1[2], Y2[3])\n",
        "b0 = [(b0[0]/763)*1440, (b0[1]/763)*1440, (b0[2]/779)*1440, (b0[3]/779)*1440]\n",
        "\n",
        "b1 = np.array(one_box1)\n",
        "b1 = [(b1[0]/763)*1440, (b1[1]/763)*1440, (b1[2]/779)*1440, (b1[3]/779)*1440]\n",
        "\n",
        "b2 = np.array(one_box2)\n",
        "b2 = [(b2[0]/763)*1440, (b2[1]/763)*1440, (b2[2]/779)*1440, (b2[3]/779)*1440]\n",
        "\n",
        "b3 = np.array(one_box3)\n",
        "b3 = [(b3[0]/763)*1440, (b3[1]/763)*1440, (b3[2]/779)*1440, (b3[3]/779)*1440]\n",
        "\n",
        "b4 = np.array(one_box4)\n",
        "b4 = [(b4[0]/763)*1440, (b4[1]/763)*1440, (b4[2]/779)*1440, (b4[3]/779)*1440]\n",
        "\n",
        "b5 = np.array(one_box5)\n",
        "b5 = [(b5[0]/763)*1440, (b5[1]/763)*1440, (b5[2]/779)*1440, (b5[3]/779)*1440]\n",
        "\n",
        "\"\"\"\n",
        "b0 = b0.tolist()\n",
        "b1 = b1.tolist()\n",
        "b2 = b2.tolist()\n",
        "b3 = b3.tolist()\n",
        "b4 = b4.tolist()\n",
        "b5 = b5.tolist()\n",
        "\"\"\"\n",
        "x0, y0 ,w0, h0 = b0\n",
        "x1, y1, w1, h1 = b1\n",
        "x2, y2, w2, h2 = b2\n",
        "\n",
        "x3, y3, w3, h3 = b3\n",
        "x4, y4, w4, h4 = b4\n",
        "x5, y5, w5, h5 = b5\n",
        "\"\"\"\n",
        "x6, y6, w6, h6 = one_box6\n",
        "x7, y7, w7, h7 = one_box7\n",
        "x8, y8, w8, h8 = one_box8\n",
        "x9, y9, w9, h9 = one_box9\n",
        "\n",
        "x10, y10, w10, h10 = one_box10\n",
        "x11, y11, w11, h11 = one_box11\n",
        "x12, y12, w12, h12 = one_box12\n",
        "x13, y13, w13, h13 = one_box13\n",
        "x14, y14, w14, h14 = one_box14\n",
        "\n",
        "\"\"\"\n",
        "bbox0 = [x0, w0, y0, h0]\n",
        "bbox1 = [x1, w1, y1, h1]\n",
        "bbox2 = [x2, w2, y2, h2]\n",
        "\n",
        "bbox3 = [x3, w3, y3, h3]\n",
        "bbox4 = [x4, w4, y4, h4]\n",
        "bbox5 = [x5, w5, y5,h5]\n",
        "\"\"\"\n",
        "bbox6 = [x6, w6, y6, h6]\n",
        "bbox7 = [x7, w7, y7, h7]\n",
        "bbox8 = [x8, w8, y8, h8]\n",
        "bbox9 = [x9, w9, y9, h9]\n",
        "bbox10 = [x10, w10, y10, h10]\n",
        "bbox11 = [x11, w11, y11, h11]\n",
        "bbox12 = [x12, w12, y12, h12]\n",
        "bbox13 = [x13, w13, y13, h13]\n",
        "bbox14 = [x14, w14, y14, h4]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "bbox0 = torch.tensor(bbox0, dtype=torch.float32)\n",
        "bbox1 = torch.tensor(bbox1, dtype=torch.float32)\n",
        "bbox2 = torch.tensor(bbox2, dtype=torch.float32)\n",
        "\n",
        "bbox3 = torch.tensor(bbox3, dtype=torch.float32)\n",
        "bbox4 = torch.tensor(bbox4, dtype=torch.float32)\n",
        "bbox5 = torch.tensor(bbox5, dtype=torch.float32)\n",
        "\n",
        "\"\"\"\n",
        "bbox6 = torch.tensor(bbox6, dtype=torch.int)\n",
        "bbox7 = torch.tensor(bbox7, dtype=torch.int)\n",
        "bbox8 = torch.tensor(bbox8, dtype=torch.int)\n",
        "bbox9 = torch.tensor(bbox9, dtype=torch.int)\n",
        "bbox10 = torch.tensor(bbox10, dtype=torch.int)\n",
        "bbox11 = torch.tensor(bbox11, dtype=torch.int)\n",
        "bbox12 = torch.tensor(bbox12, dtype=torch.int)\n",
        "bbox13 = torch.tensor(bbox13, dtype=torch.int)\n",
        "bbox14 = torch.tensor(bbox14, dtype=torch.int)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "vogNPKfeF4XQ",
        "outputId": "8273ae2f-eddf-4c2e-f9ca-3ec2cf453155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nbbox6 = torch.tensor(bbox6, dtype=torch.int)\\nbbox7 = torch.tensor(bbox7, dtype=torch.int)\\nbbox8 = torch.tensor(bbox8, dtype=torch.int)\\nbbox9 = torch.tensor(bbox9, dtype=torch.int)\\nbbox10 = torch.tensor(bbox10, dtype=torch.int)\\nbbox11 = torch.tensor(bbox11, dtype=torch.int)\\nbbox12 = torch.tensor(bbox12, dtype=torch.int)\\nbbox13 = torch.tensor(bbox13, dtype=torch.int)\\nbbox14 = torch.tensor(bbox14, dtype=torch.int)\\n\\n#image1 = cv2.imread('/content/gdrive/MyDrive/tif_image_files/images_with_contrails/LC08_L1TP_021030_20180224_20180308_01_T1_B10.png')\\n\\ncv2.rectangle(image1, (int(x0),int(y0)), (int(w0), int(h0)),(0,0,255),-1)\\nimage1 = np.array(image1)\\ncv2_imshow(image1)\\ncv2.rectangle\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the normalized x and y coordinates of bounding box\n",
        "print (bbox0)\n",
        "print (bbox1)\n",
        "print (bbox2)\n",
        "\n",
        "print (bbox3)\n",
        "print (bbox4)\n",
        "print (bbox5)\n",
        "\"\"\"\n",
        "print (bbox6)\n",
        "print (bbox7)\n",
        "print (bbox8)\n",
        "print (bbox9)\n",
        "print (bbox10)\n",
        "print (bbox11)\n",
        "print (bbox12)\n",
        "print (bbox13)\n",
        "print (bbox14)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "BnCUKyeDkR0s",
        "outputId": "7f89f4ba-838c-4f7f-854d-01477931e9fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 586.2668,  927.3120,  816.4215, 1000.8277])\n",
            "tensor([136.3754, 617.9800, 178.6695, 844.5350])\n",
            "tensor([ 347.4684, 1174.6628,  421.5067, 1200.2650])\n",
            "tensor([ 616.9541,  966.4082,  871.4359, 1026.4298])\n",
            "tensor([789.8485, 839.9323, 864.2642, 850.4318])\n",
            "tensor([ 419.6760, 1178.2306,  505.9250, 1202.3723])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint (bbox6)\\nprint (bbox7)\\nprint (bbox8)\\nprint (bbox9)\\nprint (bbox10)\\nprint (bbox11)\\nprint (bbox12)\\nprint (bbox13)\\nprint (bbox14)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "bbox0 = bbox0.unsqueeze(0)\n",
        "bbox1 = bbox1.unsqueeze(0)\n",
        "bbox2 = bbox2.unsqueeze(0)\n",
        "\n",
        "bbox3 = bbox3.unsqueeze(0)\n",
        "bbox4 = bbox4.unsqueeze(0)\n",
        "bbox5 = bbox5.unsqueeze(0)\n",
        "\"\"\"\n",
        "bbox6 = bbox6.unsqueeze(0)\n",
        "bbox7 = bbox7.unsqueeze(0)\n",
        "bbox8 = bbox8.unsqueeze(0)\n",
        "bbox9 = bbox9.unsqueeze(0)\n",
        "bbox10 = bbox10.unsqueeze(0)\n",
        "bbox11 = bbox11.unsqueeze(0)\n",
        "bbox12 = bbox12.unsqueeze(0)\n",
        "bbox13 = bbox13.unsqueeze(0)\n",
        "bbox14 = bbox14.unsqueeze(0)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "0wsytT3WEwch",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e944f939-7cca-4990-9acd-f10db872b8da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nbbox6 = bbox6.unsqueeze(0)\\nbbox7 = bbox7.unsqueeze(0)\\nbbox8 = bbox8.unsqueeze(0)\\nbbox9 = bbox9.unsqueeze(0)\\nbbox10 = bbox10.unsqueeze(0)\\nbbox11 = bbox11.unsqueeze(0)\\nbbox12 = bbox12.unsqueeze(0)\\nbbox13 = bbox13.unsqueeze(0)\\nbbox14 = bbox14.unsqueeze(0)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# draw red bounding box on image, that should enclose the annotations\n",
        "img = draw_bounding_boxes(img, bbox0, width=2, colors=(255,255,0))\n",
        "img = draw_bounding_boxes(img, bbox1, width=2, colors=(255,255,0))\n",
        "img = draw_bounding_boxes(img, bbox2, width=2, colors=(255,255,0))\n",
        "\n",
        "img = draw_bounding_boxes(img, bbox3, width=1, colors=(255,255,0))\n",
        "img = draw_bounding_boxes(img, bbox4, width=1, colors=(255,255,0))\n",
        "img = draw_bounding_boxes(img, bbox5, width=1, colors=(255,255,0))\n",
        "\"\"\"\n",
        "img = draw_bounding_boxes(img, bbox6, width=1, colors=(255,0,0))\n",
        "img = draw_bounding_boxes(img, bbox7, width=1, colors=(255,0,0))\n",
        "img = draw_bounding_boxes(img, bbox8, width=1, colors=(255,0,0))\n",
        "img = draw_bounding_boxes(img, bbox9, width=1, colors=(255,0,0))\n",
        "\n",
        "img = draw_bounding_boxes(img, bbox10, width=1, colors=(255,0,0))\n",
        "img = draw_bounding_boxes(img, bbox11, width=1, colors=(255,0,0))\n",
        "img = draw_bounding_boxes(img, bbox12, width=1, colors=(255,0,0))\n",
        "img = draw_bounding_boxes(img, bbox13, width=1, colors=(255,0,0))\n",
        "img = draw_bounding_boxes(img, bbox14, width=1, colors=(255,0,0))\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "shGGHRHgFBy6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "fb427d32-f499-4398-a1a2-0d617a58ea6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimg = draw_bounding_boxes(img, bbox6, width=1, colors=(255,0,0))\\nimg = draw_bounding_boxes(img, bbox7, width=1, colors=(255,0,0))\\nimg = draw_bounding_boxes(img, bbox8, width=1, colors=(255,0,0))\\nimg = draw_bounding_boxes(img, bbox9, width=1, colors=(255,0,0))\\n\\nimg = draw_bounding_boxes(img, bbox10, width=1, colors=(255,0,0))\\nimg = draw_bounding_boxes(img, bbox11, width=1, colors=(255,0,0))\\nimg = draw_bounding_boxes(img, bbox12, width=1, colors=(255,0,0))\\nimg = draw_bounding_boxes(img, bbox13, width=1, colors=(255,0,0))\\nimg = draw_bounding_boxes(img, bbox14, width=1, colors=(255,0,0))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform image to PIL image\n",
        "img = torchvision.transforms.ToPILImage()(img)\n",
        "img.show()"
      ],
      "metadata": {
        "id": "S9KKpGSEYYEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save PIL image\n",
        "img.save('img0.jpeg')"
      ],
      "metadata": {
        "id": "kxiNwjp8bLtc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}